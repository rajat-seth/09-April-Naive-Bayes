{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48dfb007-e02d-4bf1-83c7-313ebd837563",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cf884b-7251-4e90-883e-4c8b203b8a4e",
   "metadata": {},
   "source": [
    "# Explanation of Bayes' theorem\n",
    "\n",
    "Bayes' theorem is a fundamental concept in probability theory and statistics. It describes the relationship between conditional probabilities, which are the probabilities of events occurring given that certain other events have occurred. The theorem is named after the 18th-century mathematician and theologian Thomas Bayes.\n",
    "\n",
    "Mathematically, Bayes' theorem can be expressed as follows:\n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "Where:\n",
    "- P(A|B) represents the conditional probability of event A occurring given that event B has occurred.\n",
    "- P(B|A) represents the conditional probability of event B occurring given that event A has occurred.\n",
    "- P(A) is the probability of event A occurring.\n",
    "- P(B) is the probability of event B occurring.\n",
    "\n",
    "In words, Bayes' theorem states that the probability of event A occurring given that event B has occurred is proportional to the likelihood of event B occurring given that event A has occurred, multiplied by the prior probability of event A occurring, and divided by the overall probability of event B occurring.\n",
    "\n",
    "Bayes' theorem has applications in various fields, including statistics, machine learning, medical diagnosis, and more. It allows us to update our beliefs or probabilities about an event based on new evidence or information. It forms the foundation for Bayesian inference, a powerful approach to reasoning under uncertainty.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff7ac19-db06-4c02-a4e0-f40337feda4f",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7990a1e-1984-4276-a5d4-37d37e013e56",
   "metadata": {},
   "source": [
    "# Given values\n",
    "P_A = ...  # Probability of event A occurring\n",
    "P_B_given_A = ...  # Probability of event B occurring given event A has occurred\n",
    "P_B = ...  # Probability of event B occurring\n",
    "\n",
    "# Applying Bayes' theorem formula\n",
    "P_A_given_B = (P_B_given_A * P_A) / P_B\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5b821d-53a6-45d4-a47b-c1d1d1f23ab7",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab29e2a-a8dd-4d0f-8b94-e3c9bf874875",
   "metadata": {},
   "source": [
    "Bayes' theorem is widely used in various fields to make informed decisions, update beliefs, and perform probabilistic reasoning under uncertainty. Here are some practical applications of Bayes' theorem:\n",
    "\n",
    "1. Medical Diagnosis: Bayes' theorem is used in medical diagnosis to update the probability of a disease based on new test results or patient symptoms. It helps doctors refine their diagnoses as more information becomes available.\n",
    "\n",
    "2. Spam Filtering: Email services use Bayes' theorem for spam filtering. The theorem helps determine the probability that an incoming email is spam based on the presence of certain keywords or patterns.\n",
    "\n",
    "3. Weather Forecasting: Meteorologists use Bayes' theorem to update weather predictions based on new data and observations, leading to more accurate forecasts.\n",
    "\n",
    "4. Machine Learning and Data Science: Bayes' theorem forms the foundation for Bayesian machine learning methods, such as Bayesian networks, Naive Bayes classifiers, and probabilistic graphical models. These techniques are used for various tasks like classification, regression, and clustering.\n",
    "\n",
    "5. Natural Language Processing: In language processing tasks, Bayes' theorem can be used for tasks like sentiment analysis, topic modeling, and text classification.\n",
    "\n",
    "6. A/B Testing: Bayes' theorem is used to analyze the results of A/B tests in marketing or user experience optimization. It helps assess the impact of changes and updates based on observed outcomes.\n",
    "\n",
    "7. Criminal Justice: Bayes' theorem can be applied to forensic evidence analysis, where it helps update the probability of a suspect's guilt or innocence based on new evidence.\n",
    "\n",
    "8. Financial Modeling: Bayes' theorem is used in financial modeling for risk assessment, portfolio management, and fraud detection.\n",
    "\n",
    "9. Speech Recognition: Bayes' theorem is used in speech recognition systems to refine language models and improve the accuracy of transcriptions.\n",
    "\n",
    "10. Sensor Fusion: In robotics and autonomous systems, Bayes' theorem is used for sensor fusion, combining data from multiple sensors to make informed decisions about the environment.\n",
    "\n",
    "11. Epidemiology: Bayes' theorem plays a role in disease modeling, estimating the spread of diseases, and predicting potential outbreaks.\n",
    "\n",
    "12. Quality Control: Bayes' theorem can be applied in quality control processes to update the probability of a product being defective based on inspection results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90644a7-303b-471e-889d-b3a02d47bcd0",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395f7554-d3c0-4e31-ae8a-65d7a2722eac",
   "metadata": {},
   "source": [
    "# Given values\n",
    "P_A = ...  # Probability of event A occurring\n",
    "P_B_given_A = ...  # Probability of event B occurring given event A has occurred\n",
    "P_B = ...  # Probability of event B occurring\n",
    "\n",
    "# Calculate conditional probabilities\n",
    "P_A_given_B = (P_B_given_A * P_A) / P_B\n",
    "P_B_given_A_new = (P_A_given_B * P_B) / P_A\n",
    "\n",
    "# Print the results\n",
    "print(\"Conditional Probability of A given B:\", P_A_given_B)\n",
    "print(\"Conditional Probability of B given A (reversed):\", P_B_given_A_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4092a9b6-e612-4b60-adb0-b972d6bb1ddc",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc29253-4036-4290-8c43-817bc7aa826d",
   "metadata": {},
   "source": [
    "Choosing the right type of Naive Bayes classifier for a given problem involves considering the nature of your data and the assumptions that each variant of the classifier makes. The three main types of Naive Bayes classifiers are Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes. Here's how you can make a decision:\n",
    "\n",
    "1. Gaussian Naive Bayes: This variant is suitable for continuous or real-valued data. It assumes that the features are normally distributed within each class. Use Gaussian Naive Bayes when your features can be modeled using a Gaussian (bell-shaped) distribution, and you have continuous or numeric data.\n",
    "\n",
    "2. Multinomial Naive Bayes: This variant is commonly used for text classification problems, where the features represent word counts or term frequencies. It assumes that features are discrete and can be modeled using a multinomial distribution. Multinomial Naive Bayes is suitable for problems involving counts or frequencies, such as document classification or sentiment analysis.\n",
    "\n",
    "3. Bernoulli Naive Bayes: Similar to Multinomial Naive Bayes, this variant is also suitable for text classification tasks. However, it assumes that features are binary (0 or 1), representing the presence or absence of a feature. Bernoulli Naive Bayes is often used for problems like spam detection, where the presence of certain keywords determines the class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba30876d-2301-4f7b-a4b3-e4e372a4427f",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d87483f-2f0a-4062-a2ff-c95f54887a75",
   "metadata": {},
   "source": [
    "Choosing the right type of Naive Bayes classifier for a given problem involves considering the nature of your data and the assumptions that each variant of the classifier makes. The three main types of Naive Bayes classifiers are Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes. Here's how you can make a decision:\n",
    "\n",
    "Gaussian Naive Bayes: This variant is suitable for continuous or real-valued data. It assumes that the features are normally distributed within each class. Use Gaussian Naive Bayes when your features can be modeled using a Gaussian (bell-shaped) distribution, and you have continuous or numeric data.\n",
    "\n",
    "Multinomial Naive Bayes: This variant is commonly used for text classification problems, where the features represent word counts or term frequencies. It assumes that features are discrete and can be modeled using a multinomial distribution. Multinomial Naive Bayes is suitable for problems involving counts or frequencies, such as document classification or sentiment analysis.\n",
    "\n",
    "Bernoulli Naive Bayes: Similar to Multinomial Naive Bayes, this variant is also suitable for text classification tasks. However, it assumes that features are binary (0 or 1), representing the presence or absence of a feature. Bernoulli Naive Bayes is often used for problems like spam detection, where the presence of certain keywords determines the class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0039d90-d296-4aa8-82e5-8153a591f54f",
   "metadata": {},
   "source": [
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b202f53-40be-4806-b9d3-d072e7776427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
